---
title: "Untitled"
format: pdf
editor: visual
---

# Project Name

## Preston O'Connor, Khoa Dao

### 4/1/2025

### Introduction

```{r}
# Upload the code pacakges here
library(tidyverse)
library(GGally)
library(broom)
library(ggplot2)
library(corrplot)
library(dplyr)

data <- read_csv("diabetes_prediction_dataset.csv")
head(data)
```

### Data Description

The dataset used for this analysis is the **Diabetes Prediction Dataset**, sourced from Kaggle (<https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset/data>). This dataset contains several health-related features to predict the likelihood of diabetes. Below is a detailed description of the data structure, variable introductions, data size, and initial data cleaning process.

#### Data Structure:

The dataset consists of rows and columns, where each row corresponds to an individual, and the columns represent different health-related variables. The key variables (features) in the dataset are:

-   `age`: Age of the patient.

-   `gender`: Gender of the patient (binary variable: Male/Female).

-   `bmi`: Body mass index (weight in kg / height in mÂ²).

-   `hypertension`: Whether the individual has hypertension (binary variable: 1 for yes, 0 for no).

-   `heart_disease`: Whether the individual has a history of heart disease (binary variable: 1 for yes, 0 for no).

-   `smoking_history`: History of smoking (binary variable: 1 for smoker, 0 for non-smoker).

-   `HbA1c_level`: Hemoglobin A1c percentage, a measure of blood glucose control over time.

-   `blood_glucose_level`: Blood glucose concentration (mg/dL).

-   `diabetes`: The target variable indicating whether the individual has diabetes (1) or not (0).

#### Data Size

The dataset originally contains 100,000 observations and 9 variables.

```{r}

continuous <- data %>% 
  select(where(is.numeric))
summary(continuous)
```

Hypertension, heart_disease, diabetes are all categorical. There is no need to standardize these values. We will standardize the rest of the following available categories

#### Data Cleaning

```{r}
#cleaned our continuous variables
remove_outliers <- function(col) {
  top_one_percent <- quantile(col, 0.99)

  col[col >= top_one_percent] <- NA  # Replace outliers with NA
  return(col)
}

# normalize all of the columns with integers
normalize_features <- function(col) {
  col_min <- min(col, na.rm = TRUE)
  col_max <- max(col, na.rm = TRUE)
  
  return((col - col_min) / (col_max - col_min))
}

cleaned_data <- data %>% 
  mutate(across(c(gender, smoking_history, hypertension, heart_disease, diabetes), as_factor), 
         across(where(is.numeric), remove_outliers)) %>% 
  filter(if_all(where(is.numeric), \(col) !is.na(col))) %>% 
  mutate(across(where(is.numeric), normalize_features))

cleaned_data
```

```{r}
# Handle outliers: Remove rows where BMI/BloodGlucose/HbA1c/Age are outliers (beyond 1.5 * IQR)
# Function to remove outliers beyond 1.5 * IQR
remove_outliers_IQR <- function(df, column) {
  Q1 <- quantile(df[[column]], 0.25, na.rm = T)
  Q3 <- quantile(df[[column]], 0.75, na.rm = T)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  df %>% filter(df[[column]] >= lower_bound & df[[column]] <= upper_bound)
}

# Remove outliers for Age, BMI, BloodGlucose, and HbA1c using the custom function
cleaned_data <- cleaned_data %>%
  remove_outliers_IQR("age") %>%
  remove_outliers_IQR("bmi") %>%
  remove_outliers_IQR("blood_glucose_level") %>%
  remove_outliers_IQR("HbA1c_level")

summary(cleaned_data)
```

#### Data Visualization

```{r}
# Histogram for Age, BMI, BloodGlucose, and HbA1c
ggplot(cleaned_data, aes(x = age)) + 
  geom_histogram(binwidth = 0.075, fill = "blue", color = "black") +
  theme_minimal() + 
  labs(title = "Age Distribution")


ggplot(cleaned_data, aes(x = bmi)) + 
  geom_histogram(binwidth = 0.075, fill = "green", color = "black") + 
  theme_minimal() + 
  labs(title = "BMI Distribution")


ggplot(cleaned_data, aes(x = blood_glucose_level)) + 
  geom_histogram(binwidth = 0.15, fill = "red", color = "black") +
  theme_minimal() + 
  labs(title = "Blood Glucose Distribution")


ggplot(cleaned_data, aes(x = HbA1c_level)) + 
  geom_histogram(binwidth = 0.15, fill = "purple", color = "black") + 
  theme_minimal() + 
  labs(title = "HbA1c Distribution")
```

```{r}
# Boxplot for Age
boxplot(cleaned_data$age, 
        main = "Boxplot of Age", 
        ylab = "Age", 
        col = "blue", 
        border = "black", 
        horizontal = FALSE)

# Boxplot for BMI
boxplot(cleaned_data$bmi, 
        main = "Boxplot of BMI", 
        ylab = "BMI", 
        col = "green", 
        border = "black", 
        horizontal = FALSE) 

# Boxplot for BloodGlucose
boxplot(cleaned_data$blood_glucose_level, 
        main = "Boxplot of Blood Glucose", 
        ylab = "Blood Glucose (mg/dL)", 
        col = "red", 
        border = "black", 
        horizontal = FALSE) 

# Boxplot for HbA1c
boxplot(cleaned_data$HbA1c_level, 
        main = "Boxplot of HbA1c", 
        ylab = "HbA1c (%)", 
        col = "purple", 
        border = "black", 
        horizontal = FALSE) 
```

```{r}
# Bar plot for Hypertension
ggplot(cleaned_data, aes(x = factor(hypertension))) +
  geom_bar(fill = "lightblue", color = "black") +
  labs(title = "Hypertension Distribution", x = "Hypertension (0 = No, 1 = Yes)", y = "Count") +
  theme_minimal()

# Bar plot for HeartDisease
ggplot(cleaned_data, aes(x = factor(heart_disease))) +
  geom_bar(fill = "lightgreen", color = "black") +
  labs(title = "Heart Disease History Distribution", x = "Heart Disease (0 = No, 1 = Yes)", y = "Count") +
  theme_minimal()

# Bar plot for SmokingHistory
ggplot(cleaned_data, aes(x = factor(smoking_history))) +
  geom_bar(fill = "lightcoral", color = "black") +
  labs(title = "Smoking History Distribution", x = "Smoking History (0 = Non-Smoker, 1 = Smoker)", y = "Count") +
  theme_minimal()

# Bar plot for Diabetes
ggplot(cleaned_data, aes(x = factor(diabetes))) +
  geom_bar(fill = "lightgrey", color = "black") +
  labs(title = "Diabetes Distribution", x = "Diabetes (0 = No Diabetes, 1 = Diabetes)", y = "Count") +
  theme_minimal()
```

### Analysis

##### Continuous variables

```{r}
continuous <- cleaned_data %>% 
  select(where(is.numeric))
summary(continuous)
```

##### Factor Variables

```{r}
cleaned_data %>%
  summarize(across(where(is.factor), n_distinct)) %>% 
  pivot_longer(cols = everything(), names_to = "variable", values_to = "count") %>% 
  ggplot(aes(x = variable, y = count)) +
  geom_bar(stat = "identity")
    

```

From the graph above, we can see that smoking history has 6 levels. This is somewhat substantial, and some levels have relatively low number of observations.

##### Feature Engineering

```{r}
cleaned_data %>% 
  count(smoking_history)


```

##### Summary Statistic

```{r}
cleaned_data %>% 
  count(diabetes) %>% 
  ggplot(aes(x = diabetes, y = n))+
  geom_bar(stat = "identity")
```

There is an extreme imbalance in the range of the distribution

```{r}
#| fig-width: 10
#| fig-height: 10

cleaned_data %>% 
  sample_n(size = 100) %>% 
  ggpairs(columns = 1:ncol(cleaned_data), diag = "blankDiag", upper = list(continuous = "points"))
```

##### Train/Test & Building Model

```{r}
set.seed(1234)

create_train_test <- function(data, size = 0.8, train = TRUE) {
  n_row = nrow(data)
  total_row = size * n_row
  train_sample <- 1: total_row
  if (train == TRUE) {
    return (data[train_sample, ])
  } else {
    return (data[-train_sample, ])
    mean(glm_pred == as.character(testing$diabetes))
  }
}

data_train <- create_train_test(cleaned_data, 0.7, train = TRUE)
data_test <- create_train_test(cleaned_data, 0.7, train = FALSE)
dim(data_train)


glm_fit <- glm(diabetes ~ ., data = data_train, family = "binomial")
predictions <- predict(glm_fit, newdata = data_test, type = "response")
glm_pred <- rep("0", nrow(data_test))
glm_pred[predictions > 0.5] = "1"

table(glm_pred)
table(data_test$diabetes)
# for the accuracy mentioned further down in reference
ac <- mean(glm_pred == data_test$diabetes)

tidy(glm_fit)
```

##### Assess Model Performance

confusion matrixes for the next two

```{r}
summary(glm_fit)
```

```{r}
table(glm_pred, data_test$diabetes)
```

#### Null Model

```{r}
null_model <- glm(diabetes ~ 1, data = data_train, family = "binomial")

# Check the summary of the null model
summary(null_model)
```

#### Our Model

```{r}
summary(glm_fit)
```

Residual deviance is less than the Null deviance which indicate significant improvements in the model

#### Model Comparison with Reduction in deviance

```{r}
anova(glm_fit, test = "Chisq")
```

### Application to GLM

##### BIC

```{r}
bic_value <- BIC(glm_fit)
print(paste("BIC:", bic_value))
```

#### 

### Model evaluation and predictions

##### Model Accuracy

```{r}
# model Accuracy (Full model due to no need for feature selection)
mean(glm_pred == data_test$diabetes)
# model Accuracy of the NULL
mean(null_model == data_test$diabetes)
```

#### likelihood Ratio Test:

```{r}
anova(null_model, glm_fit, test = "Chisq")
```

#### AIC/BIC for model comparison

```{r}

```

#### Pseudo R-Squared

```{r}
null_logLik <- logLik(null_model)

full_logLik <- logLik(glm_fit)

# McFadden's Pseudo R-squared
pseudo_r2 <- 1 - (as.numeric(full_logLik) / as.numeric(null_logLik))
print(paste("Pseudo R-squared:", pseudo_r2))
```

### Conclusion/Summary
